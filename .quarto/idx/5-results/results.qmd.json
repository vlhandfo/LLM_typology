{"title":"Results","markdown":{"yaml":{"execute":{"echo":false}},"headingText":"Results","containsRefs":false,"markdown":"\n\n\n```{python}\nimport pandas as pd\nimport altair as alt\nimport utils\n\nfrom itables import show\nfrom pathlib import Path\nfrom scipy.stats import pearsonr\n\nDATA_DIR = Path(\"../data\")\n\ntasks = [\"dev_Lemmas\", \"dev_UPOS\", \"dev_UAS\"]\n\nassert DATA_DIR.exists() and DATA_DIR.is_dir(), \"Invalid path to data directory.\"\n\nFEATS_DF = pd.read_csv(DATA_DIR / \"feature_values.csv\", index_col=0)\np90_df = pd.read_csv(DATA_DIR / \"p90_df.csv\")\n\ndelta_df = pd.read_csv(DATA_DIR / \"delta_df.csv\")\n\ndf = pd.read_csv(DATA_DIR / \"metrics_df.csv\")\nfit_df = pd.read_csv(DATA_DIR / \"fit_data.csv\")\n```\n\n## Learning Curve Variation\n\n### Variation of a Model\n:::{#fig-curve-variation}\n```{python}\nlangs = ['ja', 'en', 'zh']\ndomain = [0, 101]\ntitle = \"Learning Curves for Selected Models\"\n\ncharts = utils.get_charts_for_langs(langs, df[df['Task'].isin(tasks)], fit_df[fit_df['Task'].isin(tasks)], domain)\n\nalt.vconcat(*charts).properties(\n    title=alt.Title(title, anchor=\"middle\", offset=15)\n).show()\n```\n\nWhile the learning curves for English model are rather homogenous, it is not the case for the Japanese model. The learning curves for the Chinese models on UAS and Lemmas are similar to the English model, however, all checkpoints of the Chinese model achieve $> 99\\%$ accuracy on lemmatization.\n::: \n\n### Variation on the Same Task\n\n:::{#fig-task-variation fig-align=\"center\"}\n```{python}\ntitle=\"Learning Curve for All Languages on Selected Tasks\"\n\ncharts = utils.get_charts_for_tasks(tasks, df, fit_df)\n\nalt.hconcat(*charts\n).properties(\n    title=alt.Title(title, anchor=\"middle\", offset=15)\n).show()\n```\n\nGiven a task, different models may learn at different rates than others.\n:::\n\n## Delta Variation\n\n:::{#fig-delta-variation fig-align=\"center\"}\n```{python}\nselected_languages = [\"Vietnamese\", \"Chinese\", \"English\", \"Korean\", \"Russian\"]\ny_domain = [0,55]\n\nmelted_df = delta_df[['Language'] + tasks].melt(id_vars='Language', \n              var_name='Task', \n              value_name='Delta'\n            )\nmelted_df = melted_df[melted_df['Language'].isin(selected_languages)]\n\ncharts = []\nfor lang in selected_languages:\n    _df = melted_df[melted_df['Language'] == lang]\n    charts.append(alt.Chart(_df).mark_bar().encode(\n        x=alt.X(\n            \"Task:N\", \n            sort=None, \n            axis=alt.Axis(labelAngle=-45, title=None)\n        ),\n        y=alt.Y(\n            \"Delta:Q\", \n            scale=alt.Scale(domain=y_domain)\n        ),\n        tooltip=[\"Task:N\", \"Delta:Q\", \"Language:N\"]\n    ).properties(\n        title=lang,\n        height=125,\n        width=75\n    ))\n\nalt.hconcat(*charts).show()\n```\n\nThe amount of improvement (delta) varies across different tasks and models.\n:::\n\n## Typological Correlations\n\n```{python}\ndef get_correlation_df(feats_df, target_df, threshold=0.05):\n    GROUPS = ['marking', 'formation', 'determiners', 'case', 'lexicon', 'order']\n    res = []\n    for task in target_df.columns:\n        # define the target\n        target = target_df[task]\n        for group in GROUPS:\n            # get the subset of features in the group\n            group_feats = feats_df[feats_df['Group'] == group].drop(columns=\"Group\")\n            # convert to language vectors\n            lang_vec = group_feats.T\n            # remove features with low variance\n            for c in lang_vec.columns:\n                if lang_vec[c].value_counts()[0] <= 2:\n                    lang_vec = lang_vec.drop(columns=c)\n                elif lang_vec[c].value_counts()[1] <= 2:\n                    lang_vec = lang_vec.drop(columns=c)\n            # add group sum as predictor\n            lang_vec[f'{group}_sum'] = lang_vec.sum(axis=1)\n            lang_vec = pd.concat((lang_vec, target), axis=1).sort_values(task).drop('Indonesian')\n            \n            # Calculate the pearson correlation\n            for c in lang_vec.columns[:-1]:\n                _corr = pearsonr(lang_vec[c], lang_vec[task])\n                if _corr.pvalue < threshold:\n                    res.append([\n                                task, \n                                group,\n                                c, \n                                _corr.statistic,\n                                _corr.pvalue\n                                ])\n    res_df = pd.DataFrame(res, columns=['Task', 'Group', \"Feature\", \"Correlation\", \"PValue\"]).sort_values('Correlation', ascending=False)\n    res_df = res_df.merge(FEATS_DF[['Feature', 'Name']], left_on='Feature', right_on='Feature', how='left'\n                      )\n    return res_df\n\nfeats_df = FEATS_DF.copy(\n    ).set_index(\"Feature\", drop=True\n    ).drop(columns=[\"Name\"])\n```\n\n:::{#tbl-corr-p90}\n```{python}\np90_corr = get_correlation_df(\n            feats_df, \n            p90_df.set_index('Language'), \n            threshold=0.01\n            )\np90_corr['Feature'] = p90_corr['Feature'] + \" (\" + p90_corr['Group'] + \")\"\np90_corr = p90_corr.set_index('Feature', drop=True\n            ).drop(columns=['PValue', 'Group']\n            ).sort_index()\nshow(p90_corr[['Name', 'Task', 'Correlation']],\n    classes=\"compact\",\n    lengthMenu=[5, 10]\n)\n```\n\nFeature correlations with P90 and pvalue <0.01.\n:::\n\n:::{#tbl-corr-delta}\n```{python}\ndelta_corr = get_correlation_df(\n            feats_df, \n            delta_df.set_index('Language'), \n            threshold=0.01\n            )\ndelta_corr['Feature'] = delta_corr['Feature'] + \" (\" + delta_corr['Group'] + \")\"\ndelta_corr = delta_corr.set_index('Feature', drop=True\n            ).drop(columns=['PValue', 'Group']\n            ).sort_index()\nshow(delta_corr[['Name', 'Task', 'Correlation']],\n    classes=\"compact\",\n    lengthMenu=[5, 10]\n)\n```\n\nFeature correlations with Delta and pvalue <0.01.\n:::","srcMarkdownNoYaml":"\n\n# Results\n\n```{python}\nimport pandas as pd\nimport altair as alt\nimport utils\n\nfrom itables import show\nfrom pathlib import Path\nfrom scipy.stats import pearsonr\n\nDATA_DIR = Path(\"../data\")\n\ntasks = [\"dev_Lemmas\", \"dev_UPOS\", \"dev_UAS\"]\n\nassert DATA_DIR.exists() and DATA_DIR.is_dir(), \"Invalid path to data directory.\"\n\nFEATS_DF = pd.read_csv(DATA_DIR / \"feature_values.csv\", index_col=0)\np90_df = pd.read_csv(DATA_DIR / \"p90_df.csv\")\n\ndelta_df = pd.read_csv(DATA_DIR / \"delta_df.csv\")\n\ndf = pd.read_csv(DATA_DIR / \"metrics_df.csv\")\nfit_df = pd.read_csv(DATA_DIR / \"fit_data.csv\")\n```\n\n## Learning Curve Variation\n\n### Variation of a Model\n:::{#fig-curve-variation}\n```{python}\nlangs = ['ja', 'en', 'zh']\ndomain = [0, 101]\ntitle = \"Learning Curves for Selected Models\"\n\ncharts = utils.get_charts_for_langs(langs, df[df['Task'].isin(tasks)], fit_df[fit_df['Task'].isin(tasks)], domain)\n\nalt.vconcat(*charts).properties(\n    title=alt.Title(title, anchor=\"middle\", offset=15)\n).show()\n```\n\nWhile the learning curves for English model are rather homogenous, it is not the case for the Japanese model. The learning curves for the Chinese models on UAS and Lemmas are similar to the English model, however, all checkpoints of the Chinese model achieve $> 99\\%$ accuracy on lemmatization.\n::: \n\n### Variation on the Same Task\n\n:::{#fig-task-variation fig-align=\"center\"}\n```{python}\ntitle=\"Learning Curve for All Languages on Selected Tasks\"\n\ncharts = utils.get_charts_for_tasks(tasks, df, fit_df)\n\nalt.hconcat(*charts\n).properties(\n    title=alt.Title(title, anchor=\"middle\", offset=15)\n).show()\n```\n\nGiven a task, different models may learn at different rates than others.\n:::\n\n## Delta Variation\n\n:::{#fig-delta-variation fig-align=\"center\"}\n```{python}\nselected_languages = [\"Vietnamese\", \"Chinese\", \"English\", \"Korean\", \"Russian\"]\ny_domain = [0,55]\n\nmelted_df = delta_df[['Language'] + tasks].melt(id_vars='Language', \n              var_name='Task', \n              value_name='Delta'\n            )\nmelted_df = melted_df[melted_df['Language'].isin(selected_languages)]\n\ncharts = []\nfor lang in selected_languages:\n    _df = melted_df[melted_df['Language'] == lang]\n    charts.append(alt.Chart(_df).mark_bar().encode(\n        x=alt.X(\n            \"Task:N\", \n            sort=None, \n            axis=alt.Axis(labelAngle=-45, title=None)\n        ),\n        y=alt.Y(\n            \"Delta:Q\", \n            scale=alt.Scale(domain=y_domain)\n        ),\n        tooltip=[\"Task:N\", \"Delta:Q\", \"Language:N\"]\n    ).properties(\n        title=lang,\n        height=125,\n        width=75\n    ))\n\nalt.hconcat(*charts).show()\n```\n\nThe amount of improvement (delta) varies across different tasks and models.\n:::\n\n## Typological Correlations\n\n```{python}\ndef get_correlation_df(feats_df, target_df, threshold=0.05):\n    GROUPS = ['marking', 'formation', 'determiners', 'case', 'lexicon', 'order']\n    res = []\n    for task in target_df.columns:\n        # define the target\n        target = target_df[task]\n        for group in GROUPS:\n            # get the subset of features in the group\n            group_feats = feats_df[feats_df['Group'] == group].drop(columns=\"Group\")\n            # convert to language vectors\n            lang_vec = group_feats.T\n            # remove features with low variance\n            for c in lang_vec.columns:\n                if lang_vec[c].value_counts()[0] <= 2:\n                    lang_vec = lang_vec.drop(columns=c)\n                elif lang_vec[c].value_counts()[1] <= 2:\n                    lang_vec = lang_vec.drop(columns=c)\n            # add group sum as predictor\n            lang_vec[f'{group}_sum'] = lang_vec.sum(axis=1)\n            lang_vec = pd.concat((lang_vec, target), axis=1).sort_values(task).drop('Indonesian')\n            \n            # Calculate the pearson correlation\n            for c in lang_vec.columns[:-1]:\n                _corr = pearsonr(lang_vec[c], lang_vec[task])\n                if _corr.pvalue < threshold:\n                    res.append([\n                                task, \n                                group,\n                                c, \n                                _corr.statistic,\n                                _corr.pvalue\n                                ])\n    res_df = pd.DataFrame(res, columns=['Task', 'Group', \"Feature\", \"Correlation\", \"PValue\"]).sort_values('Correlation', ascending=False)\n    res_df = res_df.merge(FEATS_DF[['Feature', 'Name']], left_on='Feature', right_on='Feature', how='left'\n                      )\n    return res_df\n\nfeats_df = FEATS_DF.copy(\n    ).set_index(\"Feature\", drop=True\n    ).drop(columns=[\"Name\"])\n```\n\n:::{#tbl-corr-p90}\n```{python}\np90_corr = get_correlation_df(\n            feats_df, \n            p90_df.set_index('Language'), \n            threshold=0.01\n            )\np90_corr['Feature'] = p90_corr['Feature'] + \" (\" + p90_corr['Group'] + \")\"\np90_corr = p90_corr.set_index('Feature', drop=True\n            ).drop(columns=['PValue', 'Group']\n            ).sort_index()\nshow(p90_corr[['Name', 'Task', 'Correlation']],\n    classes=\"compact\",\n    lengthMenu=[5, 10]\n)\n```\n\nFeature correlations with P90 and pvalue <0.01.\n:::\n\n:::{#tbl-corr-delta}\n```{python}\ndelta_corr = get_correlation_df(\n            feats_df, \n            delta_df.set_index('Language'), \n            threshold=0.01\n            )\ndelta_corr['Feature'] = delta_corr['Feature'] + \" (\" + delta_corr['Group'] + \")\"\ndelta_corr = delta_corr.set_index('Feature', drop=True\n            ).drop(columns=['PValue', 'Group']\n            ).sort_index()\nshow(delta_corr[['Name', 'Task', 'Correlation']],\n    classes=\"compact\",\n    lengthMenu=[5, 10]\n)\n```\n\nFeature correlations with Delta and pvalue <0.01.\n:::"},"formats":{"html":{"identifier":{"display-name":"HTML","target-format":"html","base-format":"html"},"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":false,"echo":false,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"ipynb-shell-interactivity":null,"plotly-connected":true,"engine":"jupyter"},"render":{"keep-tex":false,"keep-typ":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-min-runs":1,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[],"notebook-links":true},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","output-file":"results.html"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","other-links-title":"Other Links","code-links-title":"Code Links","launch-dev-container-title":"Launch Dev Container","launch-binder-title":"Launch Binder","article-notebook-label":"Article Notebook","notebook-preview-download":"Download Notebook","notebook-preview-download-src":"Download Source","notebook-preview-back":"Back to Article","manuscript-meca-bundle":"MECA Bundle","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","appendix-view-license":"View License","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","title-block-keywords":"Keywords","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","tools-share":"Share","tools-download":"Download","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-text-placeholder":"","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-wordcount":"Word Count","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items","listing-page-words":"{0} words","listing-page-filter":"Filter","draft":"Draft"},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.6.15","bibliography":["../references.bib"],"theme":"cosmo"},"extensions":{"book":{"multiFile":true}}}},"projectFormats":["html"]}